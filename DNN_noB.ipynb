{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "brurMGreRxMv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8CKjM6HWRnpf"
      },
      "outputs": [],
      "source": [
        "class DeepNeuralNetwork():\n",
        "    def __init__(self, size, epoch=10, lr=1e-4):\n",
        "        self.size = size\n",
        "        self.epoch = epoch\n",
        "        self.lr = lr\n",
        "        self.loss = []\n",
        "    \n",
        "        # we save all parameters in the neural network in this dictionary\n",
        "        self.params = self.initialization()\n",
        "    \n",
        "    \n",
        "    ##Initialization\n",
        "    def initialization(self):\n",
        "        # number of nodes in each layer\n",
        "        input_layer = self.size[0] #13\n",
        "        hidden1 = self.size[1] #24\n",
        "        hidden2 = self.size[2] #48\n",
        "        hidden3 = self.size[3] #24\n",
        "        output_layer = self.size[4] #1\n",
        "    \n",
        "        params = {\n",
        "            'W1': np.random.randn(hidden1, input_layer),\n",
        "            'W2': np.random.randn(hidden2, hidden1),\n",
        "            'W3': np.random.randn(hidden3, hidden2),\n",
        "            'W4': np.random.randn(output_layer, hidden3),\n",
        "\n",
        "            #'B1': np.random.randn(hidden1, 1),\n",
        "            #'B2': np.random.randn(hidden2, 1),\n",
        "            #'B3': np.random.randn(hidden3, 1),\n",
        "            #'B4': np.random.randn(output_layer, 1)\n",
        "        }\n",
        "        return params\n",
        "\n",
        "\n",
        "    def relu(self, x, derivative=False):\n",
        "        if derivative==True:\n",
        "            x[x > 0] = 1\n",
        "            x[x <= 0] = 0\n",
        "            return x\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "\n",
        "    ### Feedforward\n",
        "    def forward_pass(self, x_train):\n",
        "        params = self.params\n",
        "\n",
        "        # input layer activations becomes sample\n",
        "        params['I'] = x_train.reshape(13, 1)\n",
        "\n",
        "        # input layer to hidden layer 1\n",
        "        params['A1'] = np.dot(params[\"W1\"], params['I'])\n",
        "        #params['A1'] = np.dot(params[\"W1\"], params['I']) + params['B1']\n",
        "        params['R1'] = self.relu(params['A1'])\n",
        "\n",
        "        # hidden layer 1 to hidden layer 2\n",
        "        params['A2'] = np.dot(params[\"W2\"], params['A1'])\n",
        "        #params['A2'] = np.dot(params[\"W2\"], params['A1']) + params['B2']\n",
        "        params['R2'] = self.relu(params['A2'])\n",
        "\n",
        "        # hidden layer 2 to hidden layer 3\n",
        "        params['A3'] = np.dot(params[\"W3\"], params['A2']) \n",
        "        #params['A3'] = np.dot(params[\"W3\"], params['A2']) + params['B3'] \n",
        "        params['R3'] = self.relu(params['A3'])\n",
        "\n",
        "        # hidden layer 3 to output layer\n",
        "        params['O'] = np.dot(params['W4'], params['R3'])\n",
        "        #params['O'] = np.dot(params['W4'], params['R3']) + params['B4']\n",
        "\n",
        "        return params['O']\n",
        "\n",
        "\n",
        "    def lossfunction(self, output, y_train):\n",
        "        return (output-y_train)**2\n",
        "\n",
        "\n",
        "\n",
        "    ### Backpropagation\n",
        "    def backward_pass(self, y_train, output):\n",
        "        params = self.params\n",
        "        change_w = {}\n",
        "\n",
        "        # Calculate W4 update\n",
        "        error_O = output - y_train\n",
        "\n",
        "        # Calculate W3 update\n",
        "        error_R3 = np.multiply( np.dot(params['W4'].T, error_O), self.relu(params['A3'], derivative=True) )\n",
        "\n",
        "        # Calculate W2 update\n",
        "        error_R2 = np.multiply( np.dot(params['W3'].T, error_R3), self.relu(params['A2'], derivative=True) )\n",
        "\n",
        "        # Calculate W1 update\n",
        "        error_R1 = np.multiply( np.dot(params['W2'].T, error_R2), self.relu(params['A1'], derivative=True) )\n",
        "        \n",
        "        \n",
        "        change_w['W1'] = np.dot(params['I'], error_R1.T).T\n",
        "        change_w['W2'] = np.dot(params['R1'], error_R2.T).T\n",
        "        change_w['W3'] = np.dot(params['R2'], error_R3.T).T\n",
        "        change_w['W4'] = np.dot(params['R3'], error_O.T).T\n",
        "        return change_w\n",
        "\n",
        "\n",
        "    def update_network_parameters(self, changes_to_w):\n",
        "        for key, value in changes_to_w.items():\n",
        "            self.params[key] -= self.lr * value\n",
        "\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        start_time = time.time()\n",
        "        for iteration in range(self.epoch):\n",
        "            loss_list = []\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                output = self.forward_pass(x.reshape(13, 1))\n",
        "                changes_to_w = self.backward_pass(y.reshape(1, 1), output)\n",
        "                self.update_network_parameters(changes_to_w)\n",
        "                loss_list.append(self.lossfunction(float(self.forward_pass(x.reshape(13, 1))), float(y)))\n",
        "            self.loss.append(np.mean(loss_list))\n",
        "            if (iteration) % 100 == 0:\n",
        "                print('Epoch: {0}, Time Spent: {1:.2f}s'.format(\n",
        "                    iteration, time.time() - start_time\n",
        "                ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "444fE4Y1R19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Time Spent: 0.04s\n",
            "Epoch: 100, Time Spent: 4.43s\n",
            "Epoch: 200, Time Spent: 8.75s\n",
            "Epoch: 300, Time Spent: 13.05s\n",
            "Epoch: 400, Time Spent: 17.37s\n",
            "Epoch: 500, Time Spent: 21.71s\n",
            "Epoch: 600, Time Spent: 26.01s\n",
            "Epoch: 700, Time Spent: 30.37s\n",
            "Epoch: 800, Time Spent: 34.72s\n",
            "Epoch: 900, Time Spent: 39.09s\n",
            "Epoch: 1000, Time Spent: 43.38s\n",
            "Epoch: 1100, Time Spent: 47.68s\n",
            "Epoch: 1200, Time Spent: 52.00s\n",
            "Epoch: 1300, Time Spent: 56.30s\n",
            "Epoch: 1400, Time Spent: 60.71s\n",
            "Epoch: 1500, Time Spent: 65.14s\n",
            "Epoch: 1600, Time Spent: 69.52s\n",
            "Epoch: 1700, Time Spent: 73.96s\n",
            "Epoch: 1800, Time Spent: 78.34s\n",
            "Epoch: 1900, Time Spent: 82.72s\n",
            "Epoch: 2000, Time Spent: 86.96s\n",
            "Epoch: 2100, Time Spent: 91.30s\n",
            "Epoch: 2200, Time Spent: 95.62s\n",
            "Epoch: 2300, Time Spent: 99.97s\n",
            "Epoch: 2400, Time Spent: 104.38s\n",
            "Epoch: 2500, Time Spent: 108.79s\n",
            "Epoch: 2600, Time Spent: 113.16s\n",
            "Epoch: 2700, Time Spent: 117.52s\n",
            "Epoch: 2800, Time Spent: 121.85s\n",
            "Epoch: 2900, Time Spent: 126.14s\n",
            "Epoch: 3000, Time Spent: 130.55s\n",
            "Epoch: 3100, Time Spent: 134.92s\n",
            "Epoch: 3200, Time Spent: 139.33s\n",
            "Epoch: 3300, Time Spent: 143.77s\n",
            "Epoch: 3400, Time Spent: 148.04s\n",
            "Epoch: 3500, Time Spent: 152.37s\n",
            "Epoch: 3600, Time Spent: 156.65s\n",
            "Epoch: 3700, Time Spent: 161.01s\n",
            "Epoch: 3800, Time Spent: 165.38s\n",
            "Epoch: 3900, Time Spent: 169.77s\n",
            "Epoch: 4000, Time Spent: 174.15s\n",
            "Epoch: 4100, Time Spent: 178.50s\n",
            "Epoch: 4200, Time Spent: 182.86s\n",
            "Epoch: 4300, Time Spent: 187.24s\n",
            "Epoch: 4400, Time Spent: 191.58s\n",
            "Epoch: 4500, Time Spent: 195.98s\n",
            "Epoch: 4600, Time Spent: 200.41s\n",
            "Epoch: 4700, Time Spent: 204.79s\n",
            "Epoch: 4800, Time Spent: 209.22s\n",
            "Epoch: 4900, Time Spent: 213.63s\n",
            "Epoch: 5000, Time Spent: 218.02s\n",
            "Epoch: 5100, Time Spent: 222.33s\n",
            "Epoch: 5200, Time Spent: 226.65s\n",
            "Epoch: 5300, Time Spent: 231.02s\n",
            "Epoch: 5400, Time Spent: 235.45s\n",
            "Epoch: 5500, Time Spent: 239.88s\n",
            "Epoch: 5600, Time Spent: 244.23s\n",
            "Epoch: 5700, Time Spent: 248.59s\n",
            "Epoch: 5800, Time Spent: 252.88s\n",
            "Epoch: 5900, Time Spent: 257.28s\n",
            "Epoch: 6000, Time Spent: 261.61s\n",
            "Epoch: 6100, Time Spent: 265.93s\n",
            "Epoch: 6200, Time Spent: 270.32s\n",
            "Epoch: 6300, Time Spent: 274.74s\n",
            "Epoch: 6400, Time Spent: 279.15s\n",
            "Epoch: 6500, Time Spent: 283.46s\n",
            "Epoch: 6600, Time Spent: 287.76s\n",
            "Epoch: 6700, Time Spent: 292.14s\n",
            "Epoch: 6800, Time Spent: 296.41s\n",
            "Epoch: 6900, Time Spent: 300.81s\n",
            "Epoch: 7000, Time Spent: 305.19s\n",
            "Epoch: 7100, Time Spent: 309.54s\n",
            "Epoch: 7200, Time Spent: 313.87s\n",
            "Epoch: 7300, Time Spent: 318.19s\n",
            "Epoch: 7400, Time Spent: 322.52s\n",
            "Epoch: 7500, Time Spent: 326.79s\n",
            "Epoch: 7600, Time Spent: 331.20s\n",
            "Epoch: 7700, Time Spent: 335.54s\n",
            "Epoch: 7800, Time Spent: 339.85s\n",
            "Epoch: 7900, Time Spent: 344.18s\n",
            "Epoch: 8000, Time Spent: 348.49s\n",
            "Epoch: 8100, Time Spent: 352.89s\n",
            "Epoch: 8200, Time Spent: 357.30s\n",
            "Epoch: 8300, Time Spent: 361.72s\n",
            "Epoch: 8400, Time Spent: 366.08s\n",
            "Epoch: 8500, Time Spent: 370.45s\n",
            "Epoch: 8600, Time Spent: 374.91s\n",
            "Epoch: 8700, Time Spent: 379.37s\n",
            "Epoch: 8800, Time Spent: 383.77s\n",
            "Epoch: 8900, Time Spent: 388.07s\n",
            "Epoch: 9000, Time Spent: 392.34s\n",
            "Epoch: 9100, Time Spent: 396.63s\n",
            "Epoch: 9200, Time Spent: 400.98s\n",
            "Epoch: 9300, Time Spent: 405.40s\n",
            "Epoch: 9400, Time Spent: 409.73s\n",
            "Epoch: 9500, Time Spent: 414.13s\n",
            "Epoch: 9600, Time Spent: 418.48s\n",
            "Epoch: 9700, Time Spent: 422.77s\n",
            "Epoch: 9800, Time Spent: 427.13s\n",
            "Epoch: 9900, Time Spent: 431.54s\n",
            "Epoch: 10000, Time Spent: 435.91s\n",
            "Epoch: 10100, Time Spent: 440.33s\n",
            "Epoch: 10200, Time Spent: 444.68s\n",
            "Epoch: 10300, Time Spent: 449.05s\n",
            "Epoch: 10400, Time Spent: 453.35s\n",
            "Epoch: 10500, Time Spent: 457.65s\n",
            "Epoch: 10600, Time Spent: 461.91s\n",
            "Epoch: 10700, Time Spent: 466.19s\n",
            "Epoch: 10800, Time Spent: 470.58s\n",
            "Epoch: 10900, Time Spent: 474.93s\n",
            "Epoch: 11000, Time Spent: 479.32s\n",
            "Epoch: 11100, Time Spent: 483.67s\n",
            "Epoch: 11200, Time Spent: 487.95s\n",
            "Epoch: 11300, Time Spent: 492.22s\n",
            "Epoch: 11400, Time Spent: 496.52s\n",
            "Epoch: 11500, Time Spent: 500.93s\n",
            "Epoch: 11600, Time Spent: 505.27s\n",
            "Epoch: 11700, Time Spent: 509.63s\n",
            "Epoch: 11800, Time Spent: 514.04s\n",
            "Epoch: 11900, Time Spent: 518.33s\n",
            "Epoch: 12000, Time Spent: 522.66s\n",
            "Epoch: 12100, Time Spent: 526.94s\n",
            "Epoch: 12200, Time Spent: 531.23s\n",
            "Epoch: 12300, Time Spent: 535.62s\n",
            "Epoch: 12400, Time Spent: 539.96s\n",
            "Epoch: 12500, Time Spent: 544.35s\n",
            "Epoch: 12600, Time Spent: 548.72s\n",
            "Epoch: 12700, Time Spent: 553.06s\n",
            "Epoch: 12800, Time Spent: 557.32s\n",
            "Epoch: 12900, Time Spent: 561.66s\n",
            "Epoch: 13000, Time Spent: 566.03s\n",
            "Epoch: 13100, Time Spent: 570.43s\n",
            "Epoch: 13200, Time Spent: 574.87s\n",
            "Epoch: 13300, Time Spent: 579.25s\n",
            "Epoch: 13400, Time Spent: 583.60s\n",
            "Epoch: 13500, Time Spent: 587.95s\n",
            "Epoch: 13600, Time Spent: 592.24s\n",
            "Epoch: 13700, Time Spent: 596.60s\n",
            "Epoch: 13800, Time Spent: 600.91s\n",
            "Epoch: 13900, Time Spent: 605.24s\n",
            "Epoch: 14000, Time Spent: 609.52s\n",
            "Epoch: 14100, Time Spent: 613.87s\n",
            "Epoch: 14200, Time Spent: 618.22s\n",
            "Epoch: 14300, Time Spent: 622.49s\n",
            "Epoch: 14400, Time Spent: 626.78s\n",
            "Epoch: 14500, Time Spent: 631.08s\n",
            "Epoch: 14600, Time Spent: 635.53s\n",
            "Epoch: 14700, Time Spent: 639.88s\n",
            "Epoch: 14800, Time Spent: 644.24s\n",
            "Epoch: 14900, Time Spent: 648.58s\n",
            "Epoch: 15000, Time Spent: 652.90s\n",
            "Epoch: 15100, Time Spent: 657.22s\n",
            "Epoch: 15200, Time Spent: 661.51s\n",
            "Epoch: 15300, Time Spent: 665.89s\n",
            "Epoch: 15400, Time Spent: 670.21s\n",
            "Epoch: 15500, Time Spent: 674.59s\n",
            "Epoch: 15600, Time Spent: 678.89s\n",
            "Epoch: 15700, Time Spent: 683.24s\n",
            "Epoch: 15800, Time Spent: 687.54s\n",
            "Epoch: 15900, Time Spent: 691.92s\n",
            "Epoch: 16000, Time Spent: 696.38s\n",
            "Epoch: 16100, Time Spent: 700.80s\n",
            "Epoch: 16200, Time Spent: 705.26s\n",
            "Epoch: 16300, Time Spent: 709.69s\n",
            "Epoch: 16400, Time Spent: 714.06s\n",
            "Epoch: 16500, Time Spent: 718.40s\n",
            "Epoch: 16600, Time Spent: 722.69s\n",
            "Epoch: 16700, Time Spent: 726.92s\n",
            "Epoch: 16800, Time Spent: 731.26s\n",
            "Epoch: 16900, Time Spent: 735.61s\n",
            "Epoch: 17000, Time Spent: 739.99s\n",
            "Epoch: 17100, Time Spent: 744.33s\n",
            "Epoch: 17200, Time Spent: 748.68s\n",
            "Epoch: 17300, Time Spent: 753.03s\n",
            "Epoch: 17400, Time Spent: 757.35s\n",
            "Epoch: 17500, Time Spent: 761.63s\n",
            "Epoch: 17600, Time Spent: 766.05s\n",
            "Epoch: 17700, Time Spent: 770.50s\n",
            "Epoch: 17800, Time Spent: 774.97s\n",
            "Epoch: 17900, Time Spent: 779.40s\n",
            "Epoch: 18000, Time Spent: 783.70s\n",
            "Epoch: 18100, Time Spent: 788.02s\n",
            "Epoch: 18200, Time Spent: 792.26s\n",
            "Epoch: 18300, Time Spent: 796.64s\n",
            "Epoch: 18400, Time Spent: 800.98s\n",
            "Epoch: 18500, Time Spent: 805.31s\n",
            "Epoch: 18600, Time Spent: 809.66s\n",
            "Epoch: 18700, Time Spent: 814.06s\n",
            "Epoch: 18800, Time Spent: 818.40s\n",
            "Epoch: 18900, Time Spent: 822.69s\n",
            "Epoch: 19000, Time Spent: 827.01s\n",
            "Epoch: 19100, Time Spent: 831.40s\n",
            "Epoch: 19200, Time Spent: 835.77s\n",
            "Epoch: 19300, Time Spent: 840.21s\n",
            "Epoch: 19400, Time Spent: 844.60s\n",
            "Epoch: 19500, Time Spent: 848.95s\n",
            "Epoch: 19600, Time Spent: 853.23s\n",
            "Epoch: 19700, Time Spent: 857.54s\n",
            "Epoch: 19800, Time Spent: 861.89s\n",
            "Epoch: 19900, Time Spent: 866.27s\n",
            "Epoch: 20000, Time Spent: 870.62s\n",
            "Epoch: 20100, Time Spent: 874.99s\n",
            "Epoch: 20200, Time Spent: 879.37s\n",
            "Epoch: 20300, Time Spent: 883.70s\n",
            "Epoch: 20400, Time Spent: 888.00s\n",
            "Epoch: 20500, Time Spent: 892.32s\n",
            "Epoch: 20600, Time Spent: 896.64s\n",
            "Epoch: 20700, Time Spent: 900.99s\n",
            "Epoch: 20800, Time Spent: 905.34s\n",
            "Epoch: 20900, Time Spent: 909.66s\n",
            "Epoch: 21000, Time Spent: 914.02s\n",
            "Epoch: 21100, Time Spent: 918.42s\n",
            "Epoch: 21200, Time Spent: 922.71s\n",
            "Epoch: 21300, Time Spent: 927.01s\n",
            "Epoch: 21400, Time Spent: 931.35s\n",
            "Epoch: 21500, Time Spent: 935.70s\n",
            "Epoch: 21600, Time Spent: 940.06s\n",
            "Epoch: 21700, Time Spent: 944.41s\n",
            "Epoch: 21800, Time Spent: 948.76s\n",
            "Epoch: 21900, Time Spent: 953.05s\n",
            "Epoch: 22000, Time Spent: 957.40s\n",
            "Epoch: 22100, Time Spent: 961.78s\n",
            "Epoch: 22200, Time Spent: 966.25s\n",
            "Epoch: 22300, Time Spent: 970.67s\n",
            "Epoch: 22400, Time Spent: 975.14s\n",
            "Epoch: 22500, Time Spent: 979.56s\n",
            "Epoch: 22600, Time Spent: 983.92s\n",
            "Epoch: 22700, Time Spent: 988.20s\n",
            "Epoch: 22800, Time Spent: 992.52s\n",
            "Epoch: 22900, Time Spent: 996.88s\n",
            "Epoch: 23000, Time Spent: 1001.28s\n",
            "Epoch: 23100, Time Spent: 1005.66s\n",
            "Epoch: 23200, Time Spent: 1010.09s\n",
            "Epoch: 23300, Time Spent: 1014.42s\n",
            "Epoch: 23400, Time Spent: 1018.86s\n",
            "Epoch: 23500, Time Spent: 1023.17s\n",
            "Epoch: 23600, Time Spent: 1027.51s\n",
            "Epoch: 23700, Time Spent: 1031.85s\n",
            "Epoch: 23800, Time Spent: 1036.27s\n",
            "Epoch: 23900, Time Spent: 1040.69s\n",
            "Epoch: 24000, Time Spent: 1045.09s\n",
            "Epoch: 24100, Time Spent: 1049.38s\n",
            "Epoch: 24200, Time Spent: 1053.71s\n",
            "Epoch: 24300, Time Spent: 1057.97s\n",
            "Epoch: 24400, Time Spent: 1062.25s\n",
            "Epoch: 24500, Time Spent: 1066.68s\n",
            "Epoch: 24600, Time Spent: 1071.04s\n",
            "Epoch: 24700, Time Spent: 1075.43s\n",
            "Epoch: 24800, Time Spent: 1079.83s\n",
            "Epoch: 24900, Time Spent: 1084.17s\n",
            "Epoch: 25000, Time Spent: 1088.45s\n",
            "Epoch: 25100, Time Spent: 1092.74s\n",
            "Epoch: 25200, Time Spent: 1097.05s\n",
            "Epoch: 25300, Time Spent: 1101.46s\n",
            "Epoch: 25400, Time Spent: 1105.86s\n",
            "Epoch: 25500, Time Spent: 1110.24s\n",
            "Epoch: 25600, Time Spent: 1114.63s\n",
            "Epoch: 25700, Time Spent: 1118.95s\n",
            "Epoch: 25800, Time Spent: 1123.22s\n",
            "Epoch: 25900, Time Spent: 1127.56s\n",
            "Epoch: 26000, Time Spent: 1131.90s\n",
            "Epoch: 26100, Time Spent: 1136.20s\n",
            "Epoch: 26200, Time Spent: 1140.63s\n",
            "Epoch: 26300, Time Spent: 1144.95s\n",
            "Epoch: 26400, Time Spent: 1149.27s\n",
            "Epoch: 26500, Time Spent: 1153.57s\n",
            "Epoch: 26600, Time Spent: 1157.83s\n",
            "Epoch: 26700, Time Spent: 1162.18s\n",
            "Epoch: 26800, Time Spent: 1166.52s\n",
            "Epoch: 26900, Time Spent: 1170.90s\n",
            "Epoch: 27000, Time Spent: 1175.23s\n",
            "Epoch: 27100, Time Spent: 1179.59s\n",
            "Epoch: 27200, Time Spent: 1183.90s\n",
            "Epoch: 27300, Time Spent: 1188.24s\n",
            "Epoch: 27400, Time Spent: 1192.66s\n",
            "Epoch: 27500, Time Spent: 1197.01s\n",
            "Epoch: 27600, Time Spent: 1201.47s\n",
            "Epoch: 27700, Time Spent: 1205.78s\n",
            "Epoch: 27800, Time Spent: 1210.22s\n",
            "Epoch: 27900, Time Spent: 1214.58s\n",
            "Epoch: 28000, Time Spent: 1218.99s\n",
            "Epoch: 28100, Time Spent: 1223.40s\n",
            "Epoch: 28200, Time Spent: 1227.72s\n",
            "Epoch: 28300, Time Spent: 1232.15s\n",
            "Epoch: 28400, Time Spent: 1236.51s\n",
            "Epoch: 28500, Time Spent: 1240.91s\n",
            "Epoch: 28600, Time Spent: 1245.29s\n",
            "Epoch: 28700, Time Spent: 1249.62s\n",
            "Epoch: 28800, Time Spent: 1254.02s\n",
            "Epoch: 28900, Time Spent: 1258.30s\n",
            "Epoch: 29000, Time Spent: 1262.63s\n",
            "Epoch: 29100, Time Spent: 1266.94s\n",
            "Epoch: 29200, Time Spent: 1271.36s\n",
            "Epoch: 29300, Time Spent: 1275.74s\n",
            "Epoch: 29400, Time Spent: 1280.10s\n",
            "Epoch: 29500, Time Spent: 1284.50s\n",
            "Epoch: 29600, Time Spent: 1288.84s\n",
            "Epoch: 29700, Time Spent: 1293.18s\n",
            "Epoch: 29800, Time Spent: 1297.54s\n",
            "Epoch: 29900, Time Spent: 1302.00s\n",
            "Epoch: 30000, Time Spent: 1306.40s\n",
            "Epoch: 30100, Time Spent: 1310.88s\n",
            "Epoch: 30200, Time Spent: 1315.28s\n",
            "Epoch: 30300, Time Spent: 1319.67s\n",
            "Epoch: 30400, Time Spent: 1324.17s\n",
            "Epoch: 30500, Time Spent: 1328.57s\n",
            "Epoch: 30600, Time Spent: 1332.94s\n",
            "Epoch: 30700, Time Spent: 1337.30s\n",
            "Epoch: 30800, Time Spent: 1341.76s\n",
            "Epoch: 30900, Time Spent: 1346.26s\n",
            "Epoch: 31000, Time Spent: 1350.75s\n",
            "Epoch: 31100, Time Spent: 1355.18s\n",
            "Epoch: 31200, Time Spent: 1359.46s\n",
            "Epoch: 31300, Time Spent: 1363.79s\n",
            "Epoch: 31400, Time Spent: 1368.11s\n",
            "Epoch: 31500, Time Spent: 1372.54s\n",
            "Epoch: 31600, Time Spent: 1376.91s\n",
            "Epoch: 31700, Time Spent: 1381.38s\n",
            "Epoch: 31800, Time Spent: 1385.76s\n",
            "Epoch: 31900, Time Spent: 1390.15s\n",
            "Epoch: 32000, Time Spent: 1394.47s\n",
            "Epoch: 32100, Time Spent: 1398.83s\n",
            "Epoch: 32200, Time Spent: 1403.20s\n",
            "Epoch: 32300, Time Spent: 1407.58s\n",
            "Epoch: 32400, Time Spent: 1412.06s\n",
            "Epoch: 32500, Time Spent: 1416.51s\n",
            "Epoch: 32600, Time Spent: 1420.89s\n",
            "Epoch: 32700, Time Spent: 1425.34s\n",
            "Epoch: 32800, Time Spent: 1429.66s\n",
            "Epoch: 32900, Time Spent: 1434.03s\n",
            "Epoch: 33000, Time Spent: 1438.26s\n",
            "Epoch: 33100, Time Spent: 1442.69s\n",
            "Epoch: 33200, Time Spent: 1447.14s\n",
            "Epoch: 33300, Time Spent: 1451.59s\n",
            "Epoch: 33400, Time Spent: 1456.05s\n",
            "Epoch: 33500, Time Spent: 1460.54s\n",
            "Epoch: 33600, Time Spent: 1464.90s\n",
            "Epoch: 33700, Time Spent: 1469.32s\n",
            "Epoch: 33800, Time Spent: 1473.60s\n",
            "Epoch: 33900, Time Spent: 1477.95s\n",
            "Epoch: 34000, Time Spent: 1482.35s\n",
            "Epoch: 34100, Time Spent: 1486.80s\n",
            "Epoch: 34200, Time Spent: 1491.25s\n",
            "Epoch: 34300, Time Spent: 1495.62s\n",
            "Epoch: 34400, Time Spent: 1500.03s\n",
            "Epoch: 34500, Time Spent: 1504.47s\n",
            "Epoch: 34600, Time Spent: 1508.78s\n",
            "Epoch: 34700, Time Spent: 1513.16s\n",
            "Epoch: 34800, Time Spent: 1517.50s\n",
            "Epoch: 34900, Time Spent: 1521.96s\n",
            "Epoch: 35000, Time Spent: 1526.38s\n",
            "Epoch: 35100, Time Spent: 1530.84s\n",
            "Epoch: 35200, Time Spent: 1535.30s\n",
            "Epoch: 35300, Time Spent: 1539.68s\n",
            "Epoch: 35400, Time Spent: 1544.10s\n",
            "Epoch: 35500, Time Spent: 1548.35s\n",
            "Epoch: 35600, Time Spent: 1552.70s\n",
            "Epoch: 35700, Time Spent: 1557.04s\n",
            "Epoch: 35800, Time Spent: 1561.47s\n"
          ]
        }
      ],
      "source": [
        "boston = load_boston()\n",
        "X = boston.data #(506, 13)\n",
        "Y = boston.target.T #(506, )\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "dnn = DeepNeuralNetwork(size=[13, 24, 48, 24, 1], epoch=100000, lr=1e-10)\n",
        "dnn.train(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "TMssANBnruoM",
        "outputId": "67daf736-bf8a-4f01-bbb2-4c4726c3bea6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_val' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_23791/3862537959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
          ]
        }
      ],
      "source": [
        "predict = []\n",
        "for i in range(len(X_val)):\n",
        "    predict.append(float(dnn.forward_pass(X_val[i])))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(dnn.loss)\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.ylim(0, 1000)\n",
        "#plt.savefig(\"./DNN_Loss_Graph.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(predict, \".\", label=\"predict\")\n",
        "plt.plot(Y_val, \".\", label=\"target\")\n",
        "plt.title(\"Predict VS Target\")\n",
        "#plt.ylim(0, 100)\n",
        "plt.legend()\n",
        "#plt.savefig(\"./DNN_PredictVSTarget.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.01\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('cocker')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d71b4a57f5b7e4ec2b58110d28e1e0b0716a86dd3b71722facf3e5d85f632e9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
